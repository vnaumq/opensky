{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch vs Streaming обработка данных\n",
        "\n",
        "Этот notebook демонстрирует различия между batch и streaming обработкой данных.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Batch обработка\n",
        "\n",
        "Batch обработка - это обработка больших объемов данных за определенный период времени.\n",
        "\n",
        "### Характеристики:\n",
        "- Обработка исторических данных\n",
        "- Выполняется по расписанию (например, раз в день)\n",
        "- Обрабатывает все данные сразу\n",
        "- Более эффективна для больших объемов\n",
        "- Результаты доступны после завершения обработки\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, avg, max\n",
        "\n",
        "# Создаем Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Batch Processing Example\") \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Читаем исторические данные из S3\n",
        "batch_df = spark.read.parquet(\"s3a://raw-data/flights/*.parquet\")\n",
        "\n",
        "print(f\"Загружено {batch_df.count()} записей для batch обработки\")\n",
        "\n",
        "# Агрегация по странам\n",
        "batch_stats = batch_df \\\n",
        "    .groupBy(\"origin_country\") \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"total_flights\"),\n",
        "        avg(\"velocity\").alias(\"avg_velocity\"),\n",
        "        max(\"velocity\").alias(\"max_velocity\")\n",
        "    ) \\\n",
        "    .orderBy(\"total_flights\", ascending=False)\n",
        "\n",
        "batch_stats.show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Streaming обработка\n",
        "\n",
        "Streaming обработка - это обработка данных в реальном времени по мере их поступления.\n",
        "\n",
        "### Характеристики:\n",
        "- Обработка данных в реальном времени\n",
        "- Непрерывная обработка\n",
        "- Обрабатывает данные небольшими батчами\n",
        "- Результаты доступны сразу\n",
        "- Требует больше ресурсов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, avg, window\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
        "from pyspark.sql.functions import from_json\n",
        "\n",
        "# Создаем Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Streaming Processing Example\") \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Читаем поток из Kafka\n",
        "streaming_df = spark \\\n",
        "    .readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
        "    .option(\"subscribe\", \"raw_flights\") \\\n",
        "    .option(\"startingOffsets\", \"latest\") \\\n",
        "    .load()\n",
        "\n",
        "# Парсим JSON\n",
        "schema = StructType([\n",
        "    StructField(\"icao24\", StringType()),\n",
        "    StructField(\"origin_country\", StringType()),\n",
        "    StructField(\"velocity\", DoubleType())\n",
        "])\n",
        "\n",
        "flights = streaming_df.select(\n",
        "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")\n",
        ").select(\"data.*\")\n",
        "\n",
        "# Агрегация по окнам времени (5 минут)\n",
        "windowed_stats = flights \\\n",
        "    .withWatermark(\"processing_time\", \"1 minute\") \\\n",
        "    .groupBy(\n",
        "        window(col(\"processing_time\"), \"5 minutes\"),\n",
        "        col(\"origin_country\")\n",
        "    ) \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"flight_count\"),\n",
        "        avg(\"velocity\").alias(\"avg_velocity\")\n",
        "    )\n",
        "\n",
        "# Выводим результаты в консоль (для демонстрации)\n",
        "query = windowed_stats \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"update\") \\\n",
        "    .format(\"console\") \\\n",
        "    .start()\n",
        "\n",
        "query.awaitTermination()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Сравнение\n",
        "\n",
        "| Характеристика | Batch | Streaming |\n",
        "|----------------|-------|-----------|\n",
        "| Задержка | Высокая (часы/дни) | Низкая (секунды/минуты) |\n",
        "| Объем данных | Большой | Небольшие батчи |\n",
        "| Ресурсы | Высокие, но периодические | Постоянные |\n",
        "| Сложность | Проще | Сложнее |\n",
        "| Использование | Исторический анализ | Мониторинг в реальном времени |\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
